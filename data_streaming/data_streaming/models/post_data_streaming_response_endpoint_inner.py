# coding: utf-8

"""
    Data Streaming - OpenAPI

    The Data Streaming API allows you to manage your existing data streamings and templates. Data Streaming allows you to feed your stream processing, SIEM, and big data platforms with the event logs from your applications on Azion in real time. 

    The version of the OpenAPI document: 1.0.0
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
from inspect import getfullargspec
import json
import pprint
import re  # noqa: F401

from typing import Any, List, Optional
from pydantic import BaseModel, Field, StrictStr, ValidationError, validator
from data_streaming.models.endpoinrt_s3 import EndpoinrtS3
from data_streaming.models.endpoint_aws_kinesis_firehose import EndpointAWSKinesisFirehose
from data_streaming.models.endpoint_azure_blob_storage import EndpointAzureBlobStorage
from data_streaming.models.endpoint_azure_monitor import EndpointAzureMonitor
from data_streaming.models.endpoint_datadog import EndpointDatadog
from data_streaming.models.endpoint_default import EndpointDefault
from data_streaming.models.endpoint_elasticsearch import EndpointElasticsearch
from data_streaming.models.endpoint_google_big_query import EndpointGoogleBigQuery
from data_streaming.models.endpoint_ibmq_radar import EndpointIBMQRadar
from data_streaming.models.endpoint_kafka import EndpointKafka
from data_streaming.models.endpoint_splunk import EndpointSplunk
from typing import Union, Any, List, TYPE_CHECKING
from pydantic import StrictStr, Field

POSTDATASTREAMINGRESPONSEENDPOINTINNER_ONE_OF_SCHEMAS = ["EndpoinrtS3", "EndpointAWSKinesisFirehose", "EndpointAzureBlobStorage", "EndpointAzureMonitor", "EndpointDatadog", "EndpointDefault", "EndpointElasticsearch", "EndpointGoogleBigQuery", "EndpointIBMQRadar", "EndpointKafka", "EndpointSplunk"]

class PostDataStreamingResponseEndpointInner(BaseModel):
    """
    PostDataStreamingResponseEndpointInner
    """
    # data type: EndpointDefault
    oneof_schema_1_validator: Optional[EndpointDefault] = None
    # data type: EndpointKafka
    oneof_schema_2_validator: Optional[EndpointKafka] = None
    # data type: EndpoinrtS3
    oneof_schema_3_validator: Optional[EndpoinrtS3] = None
    # data type: EndpointGoogleBigQuery
    oneof_schema_4_validator: Optional[EndpointGoogleBigQuery] = None
    # data type: EndpointElasticsearch
    oneof_schema_5_validator: Optional[EndpointElasticsearch] = None
    # data type: EndpointAWSKinesisFirehose
    oneof_schema_6_validator: Optional[EndpointAWSKinesisFirehose] = None
    # data type: EndpointDatadog
    oneof_schema_7_validator: Optional[EndpointDatadog] = None
    # data type: EndpointIBMQRadar
    oneof_schema_8_validator: Optional[EndpointIBMQRadar] = None
    # data type: EndpointAzureMonitor
    oneof_schema_9_validator: Optional[EndpointAzureMonitor] = None
    # data type: EndpointAzureBlobStorage
    oneof_schema_10_validator: Optional[EndpointAzureBlobStorage] = None
    # data type: EndpointSplunk
    oneof_schema_11_validator: Optional[EndpointSplunk] = None
    if TYPE_CHECKING:
        actual_instance: Union[EndpoinrtS3, EndpointAWSKinesisFirehose, EndpointAzureBlobStorage, EndpointAzureMonitor, EndpointDatadog, EndpointDefault, EndpointElasticsearch, EndpointGoogleBigQuery, EndpointIBMQRadar, EndpointKafka, EndpointSplunk]
    else:
        actual_instance: Any
    one_of_schemas: List[str] = Field(POSTDATASTREAMINGRESPONSEENDPOINTINNER_ONE_OF_SCHEMAS, const=True)

    class Config:
        validate_assignment = True

    def __init__(self, *args, **kwargs):
        if args:
            if len(args) > 1:
                raise ValueError("If a position argument is used, only 1 is allowed to set `actual_instance`")
            if kwargs:
                raise ValueError("If a position argument is used, keyword arguments cannot be used.")
            super().__init__(actual_instance=args[0])
        else:
            super().__init__(**kwargs)

    @validator('actual_instance')
    def actual_instance_must_validate_oneof(cls, v):
        instance = PostDataStreamingResponseEndpointInner.construct()
        error_messages = []
        match = 0
        # validate data type: EndpointDefault
        if not isinstance(v, EndpointDefault):
            error_messages.append(f"Error! Input type `{type(v)}` is not `EndpointDefault`")
        else:
            match += 1
        # validate data type: EndpointKafka
        if not isinstance(v, EndpointKafka):
            error_messages.append(f"Error! Input type `{type(v)}` is not `EndpointKafka`")
        else:
            match += 1
        # validate data type: EndpoinrtS3
        if not isinstance(v, EndpoinrtS3):
            error_messages.append(f"Error! Input type `{type(v)}` is not `EndpoinrtS3`")
        else:
            match += 1
        # validate data type: EndpointGoogleBigQuery
        if not isinstance(v, EndpointGoogleBigQuery):
            error_messages.append(f"Error! Input type `{type(v)}` is not `EndpointGoogleBigQuery`")
        else:
            match += 1
        # validate data type: EndpointElasticsearch
        if not isinstance(v, EndpointElasticsearch):
            error_messages.append(f"Error! Input type `{type(v)}` is not `EndpointElasticsearch`")
        else:
            match += 1
        # validate data type: EndpointAWSKinesisFirehose
        if not isinstance(v, EndpointAWSKinesisFirehose):
            error_messages.append(f"Error! Input type `{type(v)}` is not `EndpointAWSKinesisFirehose`")
        else:
            match += 1
        # validate data type: EndpointDatadog
        if not isinstance(v, EndpointDatadog):
            error_messages.append(f"Error! Input type `{type(v)}` is not `EndpointDatadog`")
        else:
            match += 1
        # validate data type: EndpointIBMQRadar
        if not isinstance(v, EndpointIBMQRadar):
            error_messages.append(f"Error! Input type `{type(v)}` is not `EndpointIBMQRadar`")
        else:
            match += 1
        # validate data type: EndpointAzureMonitor
        if not isinstance(v, EndpointAzureMonitor):
            error_messages.append(f"Error! Input type `{type(v)}` is not `EndpointAzureMonitor`")
        else:
            match += 1
        # validate data type: EndpointAzureBlobStorage
        if not isinstance(v, EndpointAzureBlobStorage):
            error_messages.append(f"Error! Input type `{type(v)}` is not `EndpointAzureBlobStorage`")
        else:
            match += 1
        # validate data type: EndpointSplunk
        if not isinstance(v, EndpointSplunk):
            error_messages.append(f"Error! Input type `{type(v)}` is not `EndpointSplunk`")
        else:
            match += 1
        if match > 1:
            # more than 1 match
            raise ValueError("Multiple matches found when setting `actual_instance` in PostDataStreamingResponseEndpointInner with oneOf schemas: EndpoinrtS3, EndpointAWSKinesisFirehose, EndpointAzureBlobStorage, EndpointAzureMonitor, EndpointDatadog, EndpointDefault, EndpointElasticsearch, EndpointGoogleBigQuery, EndpointIBMQRadar, EndpointKafka, EndpointSplunk. Details: " + ", ".join(error_messages))
        elif match == 0:
            # no match
            raise ValueError("No match found when setting `actual_instance` in PostDataStreamingResponseEndpointInner with oneOf schemas: EndpoinrtS3, EndpointAWSKinesisFirehose, EndpointAzureBlobStorage, EndpointAzureMonitor, EndpointDatadog, EndpointDefault, EndpointElasticsearch, EndpointGoogleBigQuery, EndpointIBMQRadar, EndpointKafka, EndpointSplunk. Details: " + ", ".join(error_messages))
        else:
            return v

    @classmethod
    def from_dict(cls, obj: dict) -> PostDataStreamingResponseEndpointInner:
        return cls.from_json(json.dumps(obj))

    @classmethod
    def from_json(cls, json_str: str) -> PostDataStreamingResponseEndpointInner:
        """Returns the object represented by the json string"""
        instance = PostDataStreamingResponseEndpointInner.construct()
        error_messages = []
        match = 0

        # deserialize data into EndpointDefault
        try:
            instance.actual_instance = EndpointDefault.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into EndpointKafka
        try:
            instance.actual_instance = EndpointKafka.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into EndpoinrtS3
        try:
            instance.actual_instance = EndpoinrtS3.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into EndpointGoogleBigQuery
        try:
            instance.actual_instance = EndpointGoogleBigQuery.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into EndpointElasticsearch
        try:
            instance.actual_instance = EndpointElasticsearch.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into EndpointAWSKinesisFirehose
        try:
            instance.actual_instance = EndpointAWSKinesisFirehose.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into EndpointDatadog
        try:
            instance.actual_instance = EndpointDatadog.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into EndpointIBMQRadar
        try:
            instance.actual_instance = EndpointIBMQRadar.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into EndpointAzureMonitor
        try:
            instance.actual_instance = EndpointAzureMonitor.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into EndpointAzureBlobStorage
        try:
            instance.actual_instance = EndpointAzureBlobStorage.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into EndpointSplunk
        try:
            instance.actual_instance = EndpointSplunk.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))

        if match > 1:
            # more than 1 match
            raise ValueError("Multiple matches found when deserializing the JSON string into PostDataStreamingResponseEndpointInner with oneOf schemas: EndpoinrtS3, EndpointAWSKinesisFirehose, EndpointAzureBlobStorage, EndpointAzureMonitor, EndpointDatadog, EndpointDefault, EndpointElasticsearch, EndpointGoogleBigQuery, EndpointIBMQRadar, EndpointKafka, EndpointSplunk. Details: " + ", ".join(error_messages))
        elif match == 0:
            # no match
            raise ValueError("No match found when deserializing the JSON string into PostDataStreamingResponseEndpointInner with oneOf schemas: EndpoinrtS3, EndpointAWSKinesisFirehose, EndpointAzureBlobStorage, EndpointAzureMonitor, EndpointDatadog, EndpointDefault, EndpointElasticsearch, EndpointGoogleBigQuery, EndpointIBMQRadar, EndpointKafka, EndpointSplunk. Details: " + ", ".join(error_messages))
        else:
            return instance

    def to_json(self) -> str:
        """Returns the JSON representation of the actual instance"""
        if self.actual_instance is None:
            return "null"

        to_json = getattr(self.actual_instance, "to_json", None)
        if callable(to_json):
            return self.actual_instance.to_json()
        else:
            return json.dumps(self.actual_instance)

    def to_dict(self) -> dict:
        """Returns the dict representation of the actual instance"""
        if self.actual_instance is None:
            return None

        to_dict = getattr(self.actual_instance, "to_dict", None)
        if callable(to_dict):
            return self.actual_instance.to_dict()
        else:
            # primitive type
            return self.actual_instance

    def to_str(self) -> str:
        """Returns the string representation of the actual instance"""
        return pprint.pformat(self.dict())


